
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Section1.2 Data Processing Patterns Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="summary.html" />
    
    
    <link rel="prev" href="section1.1.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../INTRODUCTION.html">
            
                <a href="../INTRODUCTION.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="./">
            
                <a href="./">
            
                    
                    Chapter1 Streaming 101
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="section1.1.html">
            
                <a href="section1.1.html">
            
                    
                    Section1.1 Terminology: What Is Streaming?
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.2" data-path="section1.2.html">
            
                <a href="section1.2.html">
            
                    
                    Section1.2 Data Processing Patterns
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="summary.html">
            
                <a href="summary.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../chapter2/">
            
                <a href="../chapter2/">
            
                    
                    Chapter2 The What, Where,When, and How of Data Processing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="section1.1.html">
            
                <a href="section1.1.html">
            
                    
                    Section2.1 Roadmap
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../chapter2/section1.2.html">
            
                <a href="../chapter2/section1.2.html">
            
                    
                    Section2.2 Batch Foundations: What and Where
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../chapter2/summary0.html">
            
                <a href="../chapter2/summary0.html">
            
                    
                    Going Streaming: When and How
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../chapter2/summary.html">
            
                <a href="../chapter2/summary.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../chapter3/">
            
                <a href="../chapter3/">
            
                    
                    Chapter3  Watermarks
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../chapter3/section1.html">
            
                <a href="../chapter3/section1.html">
            
                    
                    Section3.1 Definition
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../chapter3/section2.html">
            
                <a href="../chapter3/section2.html">
            
                    
                    Section3.2 Source Watermark Creation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../chapter3/section3.html">
            
                <a href="../chapter3/section3.html">
            
                    
                    Watermark Propagation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../chapter3/section4.html">
            
                <a href="../chapter3/section4.html">
            
                    
                    Percentile Watermarks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="../chapter3/section5.html">
            
                <a href="../chapter3/section5.html">
            
                    
                    Processing-Time Watermarks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.6" data-path="../chapter3/section6.html">
            
                <a href="../chapter3/section6.html">
            
                    
                    Case Studies
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.7" data-path="../chapter3/section7.html">
            
                <a href="../chapter3/section7.html">
            
                    
                    Watermark Propagation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.8" data-path="../chapter3/summary.md">
            
                <span>
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../chapter4/">
            
                <a href="../chapter4/">
            
                    
                    Chapter 4. Advanced Windowing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../chapter4/section1.html">
            
                <a href="../chapter4/section1.html">
            
                    
                    When/Where: Processing-Time Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../chapter4/section2.html">
            
                <a href="../chapter4/section2.html">
            
                    
                    Where: Session Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../chapter4/section3.html">
            
                <a href="../chapter4/section3.html">
            
                    
                    Where: Custom Windowing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../chapter4/summary.html">
            
                <a href="../chapter4/summary.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../chapter5/">
            
                <a href="../chapter5/">
            
                    
                    Chapter5 Exactly-Once and Side Effects
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../chapter5/section1.html">
            
                <a href="../chapter5/section1.html">
            
                    
                    Why Exactly Once Matters
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../chapter5/section2.html">
            
                <a href="../chapter5/section2.html">
            
                    
                    Accuracy Versus Completeness
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../chapter5/section3.html">
            
                <a href="../chapter5/section3.html">
            
                    
                    Ensuring Exactly Once in Shuffle
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="../chapter5/section4.html">
            
                <a href="../chapter5/section4.html">
            
                    
                    Addressing Determinism
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="../chapter5/section5.html">
            
                <a href="../chapter5/section5.html">
            
                    
                    Performance
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.6" data-path="../chapter5/section6.html">
            
                <a href="../chapter5/section6.html">
            
                    
                    Exactly Once in Sources
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.7" data-path="../chapter5/section7.html">
            
                <a href="../chapter5/section7.html">
            
                    
                    Exactly Once in Sinks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.8" data-path="../chapter5/section8.html">
            
                <a href="../chapter5/section8.html">
            
                    
                    Use Cases
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.9" data-path="../chapter5/section8.html">
            
                <a href="../chapter5/section8.html">
            
                    
                    Other Systems
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.10" data-path="../chapter5/section9.html">
            
                <a href="../chapter5/section9.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../chapter6/">
            
                <a href="../chapter6/">
            
                    
                    Chapter6 Streams and Tables
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../chapter6/section1.html">
            
                <a href="../chapter6/section1.html">
            
                    
                    Stream-and-Table Basics Or: a Special Theory of Stream and Table Relativity
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../chapter6/section2.html">
            
                <a href="../chapter6/section2.html">
            
                    
                    Batch Processing Versus Streams and Tables
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../chapter6/section3.html">
            
                <a href="../chapter6/section3.html">
            
                    
                    What, Where, When, and How in a Streams and Tables World
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4" data-path="../chapter6/section4.html">
            
                <a href="../chapter6/section4.html">
            
                    
                    A General Theory of Stream and Table Relativity
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5" data-path="../chapter6/section5.html">
            
                <a href="../chapter6/section5.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../chapter7/">
            
                <a href="../chapter7/">
            
                    
                    Chapter 7. The Practicalities of Persistent State
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../chapter7/section1.html">
            
                <a href="../chapter7/section1.html">
            
                    
                    Motivation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../chapter7/section2.html">
            
                <a href="../chapter7/section2.html">
            
                    
                    Implicit State
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../chapter7/section3.html">
            
                <a href="../chapter7/section3.html">
            
                    
                    Generalized State
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.4" data-path="../chapter7/section4.html">
            
                <a href="../chapter7/section4.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../chapter8/">
            
                <a href="../chapter8/">
            
                    
                    Chapter 8. Streaming SQL
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../chapter8/section1.html">
            
                <a href="../chapter8/section1.html">
            
                    
                    What Is Streaming SQL?
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../chapter8/section2.html">
            
                <a href="../chapter8/section2.html">
            
                    
                    Looking Backward: Stream and Table Biases
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../chapter8/section3.html">
            
                <a href="../chapter8/section3.html">
            
                    
                    Looking Forward: Toward Robust Streaming SQL
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.4" data-path="../chapter8/section4.html">
            
                <a href="../chapter8/section4.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../chapter9/">
            
                <a href="../chapter9/">
            
                    
                    Chapter 9. Streaming Joins
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../chapter9/section2.html">
            
                <a href="../chapter9/section2.html">
            
                    
                    All Your Joins Are Belong to Streaming
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../chapter9/section3.html">
            
                <a href="../chapter9/section3.html">
            
                    
                    Unwindowed Joins
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../chapter9/section4.html">
            
                <a href="../chapter9/section4.html">
            
                    
                    Windowed Joins
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.4" data-path="../chapter9/section5.html">
            
                <a href="../chapter9/section5.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../chapter10/">
            
                <a href="../chapter10/">
            
                    
                    Chapter 10. The Evolution of Large-Scale Data Processing
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="../chapter10/section1.html">
            
                <a href="../chapter10/section1.html">
            
                    
                    MapReduce
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="../chapter10/section2.html">
            
                <a href="../chapter10/section2.html">
            
                    
                    Hadoop
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="../chapter10/section3.html">
            
                <a href="../chapter10/section3.html">
            
                    
                    Flume
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.4" data-path="../chapter10/section4.html">
            
                <a href="../chapter10/section4.html">
            
                    
                    Storm
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.5" data-path="../chapter10/section5.html">
            
                <a href="../chapter10/section5.html">
            
                    
                    Spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.6" data-path="../chapter10/section6.html">
            
                <a href="../chapter10/section6.html">
            
                    
                    MillWheel
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.7" data-path="../chapter10/section7.html">
            
                <a href="../chapter10/section7.html">
            
                    
                    Kafaka
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.8" data-path="../chapter10/section8.html">
            
                <a href="../chapter10/section8.html">
            
                    
                    CloudDataFlow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.9" data-path="../chapter10/section9.html">
            
                <a href="../chapter10/section9.html">
            
                    
                    Flink
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.10" data-path="../chapter10/section9.html">
            
                <a href="../chapter10/section9.html">
            
                    
                    Beam
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.11" data-path="../chapter10/section10.html">
            
                <a href="../chapter10/section10.html">
            
                    
                    Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Section1.2 Data Processing Patterns</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id="data-processing-patterns">Data Processing Patterns</h2>
<p>At this point, we have enough background established that we can begin
looking at the core types of usage patterns common across bounded and
unbounded data processing today. We look at both types of processing and,
where relevant, within the context of the two main types of engines we care
about (batch and streaming, where in this context, I&#x2019;m essentially lumping
microbatch in with streaming because the differences between the two aren&#x2019;t
terribly important at this level).</p>
<h2 id="bounded-data">Bounded Data</h2>
<p>Processing bounded data is conceptually quite straightforward, and likely
familiar to everyone. In Figure 1-2, we start out on the left with a dataset full
of entropy. We run it through some data processing engine (typically batch,
though a well-designed streaming engine would work just as well), such as
MapReduce, and on the right side end up with a new structured dataset with
greater inherent value.</p>
<pre><code>Figure 1-2. Bounded data processing with a classic batch engine. A finite pool of
unstructured data on the left is run through a data processing engine, resulting in
corresponding structured data on the right.
</code></pre><p>Though there are of course infinite variations on what you can actually
calculate as part of this scheme, the overall model is quite simple. Much more
interesting is the task of processing an unbounded dataset. Let&#x2019;s now look at
the various ways unbounded data are typically processed, beginning with the
approaches used with traditional batch engines and then ending up with the
approaches you can take with a system designed for unbounded data, such as
most streaming or microbatch engines.</p>
<h2 id="unbounded-data-batch">Unbounded Data: Batch</h2>
<p>Batch engines, though not explicitly designed with unbounded data in mind,
have nevertheless been used to process unbounded datasets since batch
systems were first conceived. As you might expect, such approaches revolve</p>
<p>around slicing up the unbounded data into a collection of bounded datasets
appropriate for batch processing.</p>
<p><strong>Fixed windows</strong></p>
<p>The most common way to process an unbounded dataset using repeated runs
of a batch engine is by windowing the input data into fixed-size windows and
then processing each of those windows as a separate, bounded data source
(sometimes also called <em>tumbling windows</em> ), as in Figure 1-3. Particularly for
input sources like logs, for which events can be written into directory and file
hierarchies whose names encode the window they correspond to, this sort of
thing appears quite straightforward at first blush because you&#x2019;ve essentially
performed the time-based shuffle to get data into the appropriate event-time
windows ahead of time.</p>
<p>In reality, however, most systems still have a completeness problem to deal
with (What if some of your events are delayed en route to the logs due to a
network partition? What if your events are collected globally and must be
transferred to a common location before processing? What if your events
come from mobile devices?), which means some sort of mitigation might be
necessary (e.g., delaying processing until you&#x2019;re sure all events have been
collected or reprocessing the entire batch for a given window whenever data
arrive late).</p>
<pre><code>Figure 1-3. Unbounded data processing via ad hoc fixed windows with a classic batch
engine. An unbounded dataset is collected up front into finite, fixed-size windows of
bounded data that are then processed via successive runs a of classic batch engine.
</code></pre><p><strong>Sessions</strong></p>
<p>This approach breaks down even more when you try to use a batch engine to
process unbounded data into more sophisticated windowing strategies, like
sessions. Sessions are typically defined as periods of activity (e.g., for a
specific user) terminated by a gap of inactivity. When calculating sessions
using a typical batch engine, you often end up with sessions that are split
across batches, as indicated by the red marks in Figure 1-4. We can reduce
the number of splits by increasing batch sizes, but at the cost of increased
latency. Another option is to add additional logic to stitch up sessions from
previous runs, but at the cost of further complexity.</p>
<pre><code>Figure 1-4. Unbounded data processing into sessions via ad hoc fixed windows with a
classic batch engine. An unbounded dataset is collected up front into finite, fixed-size
windows of bounded data that are then subdivided into dynamic session windows via
successive runs a of classic batch engine.
</code></pre><p>Either way, using a classic batch engine to calculate sessions is less than
ideal. A nicer way would be to build up sessions in a streaming manner,
which we look at later on.</p>
<h2 id="unbounded-data-streaming">Unbounded Data: Streaming</h2>
<p>Contrary to the ad hoc nature of most batch-based unbounded data processing
approaches, streaming systems are built for unbounded data. As we talked
about earlier, for many real-world, distributed input sources, you not only
find yourself dealing with unbounded data, but also data such as the
following:</p>
<pre><code>Highly unordered with respect to event times, meaning that you need
some sort of time-based shuffle in your pipeline if you want to
analyze the data in the context in which they occurred.
</code></pre><pre><code>Of varying event-time skew, meaning that you can&#x2019;t just assume
you&#x2019;ll always see most of the data for a given event time X within
some constant epsilon of time Y.
</code></pre><p>There are a handful of approaches that you can take when dealing with data
that have these characteristics. I generally categorize these approaches into
four groups: time-agnostic, approximation, windowing by processing time,
and windowing by event time.</p>
<p>Let&#x2019;s now spend a little bit of time looking at each of these approaches.</p>
<p><strong>Time-agnostic</strong></p>
<p>Time-agnostic processing is used for cases in which time is essentially
irrelevant; that is, all relevant logic is data driven. Because everything about
such use cases is dictated by the arrival of more data, there&#x2019;s really nothing
special a streaming engine has to support other than basic data delivery. As a
result, essentially all streaming systems in existence support time-agnostic
use cases out of the box (modulo system-to-system variances in consistency
guarantees, of course, if you care about correctness). Batch systems are also
well suited for time-agnostic processing of unbounded data sources by simply
chopping the unbounded source into an arbitrary sequence of bounded
datasets and processing those datasets independently. We look at a couple of
concrete examples in this section, but given the straightforwardness of
handling time-agnostic processing (from a temporal perspective at least), we
won&#x2019;t spend much more time on it beyond that.</p>
<p><em>Filtering</em></p>
<p>A very basic form of time-agnostic processing is filtering, an example of
which is rendered in Figure 1-5. Imagine that you&#x2019;re processing web traffic
logs and you want to filter out all traffic that didn&#x2019;t originate from a specific
domain. You would look at each record as it arrived, see if it belonged to the
domain of interest, and drop it if not. Because this sort of thing depends only
on a single element at any time, the fact that the data source is unbounded,
unordered, and of varying event-time skew is irrelevant.</p>
<pre><code>Figure 1-5. Filtering unbounded data. A collection of data (flowing left to right) of varying
types is filtered into a homogeneous collection containing a single type.
</code></pre><p><em>Inner joins</em></p>
<p>Another time-agnostic example is an inner join, diagrammed in Figure 1-6.
When joining two unbounded data sources, if you care only about the results
of a join when an element from both sources arrive, there&#x2019;s no temporal
element to the logic. Upon seeing a value from one source, you can simply
buffer it up in persistent state; only after the second value from the other
source arrives do you need to emit the joined record. (In truth, you&#x2019;d likely
want some sort of garbage collection policy for unemitted partial joins, which
would likely be time based. But for a use case with little or no uncompleted
joins, such a thing might not be an issue.)</p>
<pre><code>Figure 1-6. Performing an inner join on unbounded data. Joins are produced when
matching elements from both sources are observed.
</code></pre><p>Switching semantics to some sort of outer join introduces the data
completeness problem we&#x2019;ve talked about: after you&#x2019;ve seen one side of the
join, how do you know whether the other side is ever going to arrive or not?
Truth be told, you don&#x2019;t, so you need to introduce some notion of a timeout,
which introduces an element of time. That element of time is essentially a
form of windowing, which we&#x2019;ll look at more closely in a moment.</p>
<p><strong>Approximation algorithms</strong></p>
<p>The second major category of approaches is approximation algorithms, such
as approximate Top-N, streaming k-means, and so on. They take an
unbounded source of input and provide output data that, if you squint at them,
look more or less like what you were hoping to get, as in Figure 1-7. The
upside of approximation algorithms is that, by design, they are low overhead
and designed for unbounded data. The downsides are that a limited set of
them exist, the algorithms themselves are often complicated (which makes it
difficult to conjure up new ones), and their approximate nature limits their
utility.</p>
<p><em>Figure 1-7. Computing approximations on unbounded data. Data are run through a
complex algorithm, yielding output data that look more or less like the desired result on the
other side.</em></p>
<p>It&#x2019;s worth noting that these algorithms typically do have some element of
time in their design (e.g., some sort of built-in decay). And because they
process elements as they arrive, that time element is usually processing-time
based. This is particularly important for algorithms that provide some sort of
provable error bounds on their approximations. If those error bounds are
predicated on data arriving in order, they mean essentially nothing when you
feed the algorithm unordered data with varying event-time skew. Something
to keep in mind.</p>
<p>Approximation algorithms themselves are a fascinating subject, but as they
are essentially another example of time-agnostic processing (modulo the
temporal features of the algorithms themselves), they&#x2019;re quite straightforward
to use and thus not worth further attention, given our current focus.</p>
<p><strong>Windowing</strong></p>
<p>The remaining two approaches for unbounded data processing are both
variations of windowing. Before diving into the differences between them, I
should make it clear exactly what I mean by windowing, insomuch as we
touched on it only briefly in the previous section. Windowing is simply the
notion of taking a data source (either unbounded or bounded), and chopping
it up along temporal boundaries into finite chunks for processing. Figure 1-8
shows three different windowing patterns.</p>
<pre><code>Figure 1-8. Windowing strategies. Each example is shown for three different keys,
highlighting the difference between aligned windows (which apply across all the data) and
unaligned windows (which apply across a subset of the data).
</code></pre><p>Let&#x2019;s take a closer look at each strategy:</p>
<p>Fixed windows (aka tumbling windows)</p>
<pre><code>We discussed fixed windows earlier. Fixed windows slice time into
segments with a fixed-size temporal length. Typically (as shown in
Figure 1-9), the segments for fixed windows are applied uniformly across
the entire dataset, which is an example of aligned windows. In some
cases, it&#x2019;s desirable to phase-shift the windows for different subsets of the
data (e.g., per key) to spread window completion load more evenly over
time, which instead is an example of unaligned windows because they
vary across the data.
</code></pre><p>Sliding windows (aka hopping windows)</p>
<pre><code>6
</code></pre><pre><code>A generalization of fixed windows, sliding windows are defined by a
fixed length and a fixed period. If the period is less than the length, the
windows overlap. If the period equals the length, you have fixed
windows. And if the period is greater than the length, you have a weird
sort of sampling window that looks only at subsets of the data over time.
As with fixed windows, sliding windows are typically aligned, though
they can be unaligned as a performance optimization in certain use cases.
Note that the sliding windows in Figure 1-8 are drawn as they are to give
a sense of sliding motion; in reality, all five windows would apply across
the entire dataset.
</code></pre><p>Sessions</p>
<pre><code>An example of dynamic windows, sessions are composed of sequences of
events terminated by a gap of inactivity greater than some timeout.
Sessions are commonly used for analyzing user behavior over time, by
grouping together a series of temporally related events (e.g., a sequence
of videos viewed in one sitting). Sessions are interesting because their
lengths cannot be defined a priori; they are dependent upon the actual
data involved. They&#x2019;re also the canonical example of unaligned windows
because sessions are practically never identical across different subsets of
data (e.g., different users).
</code></pre><p>The two domains of time we discussed earlier (processing time and event
time) are essentially the two we care about. Windowing makes sense in both
domains, so let&#x2019;s look at each in detail and see how they differ. Because
processing-time windowing has historically been more common, we&#x2019;ll start
there.</p>
<p><em>Windowing by processing time</em></p>
<p>When windowing by processing time, the system essentially buffers up
incoming data into windows until some amount of processing time has
passed. For example, in the case of five-minute fixed windows, the system
would buffer data for five minutes of processing time, after which it would
treat all of the data it had observed in those five minutes as a window and
send them downstream for processing.</p>
<pre><code>7
</code></pre><pre><code>Figure 1-9. Windowing into fixed windows by processing time. Data are collected into
windows based on the order they arrive in the pipeline.
</code></pre><p>There are a few nice properties of processing-time windowing:</p>
<pre><code>It&#x2019;s simple. The implementation is extremely straightforward
because you never worry about shuffling data within time. You just
buffer things as they arrive and send them downstream when the
window closes.
</code></pre><pre><code>Judging window completeness is straightforward. Because the
system has perfect knowledge of whether all inputs for a window
have been seen, it can make perfect decisions about whether a given
window is complete. This means there is no need to be able to deal
with &#x201C;late&#x201D; data in any way when windowing by processing time.
If you&#x2019;re wanting to infer information about the source as it is
observed , processing-time windowing is exactly what you want.
Many monitoring scenarios fall into this category. Imagine tracking
the number of requests per second sent to a global-scale web service.
Calculating a rate of these requests for the purpose of detecting
outages is a perfect use of processing-time windowing.
</code></pre><p>Good points aside, there is one very big downside to processing-time
windowing: <em>if the data in question have event times associated with them,
those data must arrive in event-time order if the processing-time windows are
to reflect the reality of when those events actually happened.</em> Unfortunately,
event-time ordered data are uncommon in many real-world, distributed input
sources.</p>
<p>As a simple example, imagine any mobile app that gathers usage statistics for
later processing. For cases in which a given mobile device goes offline for
any amount of time (brief loss of connectivity, airplane mode while flying
across the country, etc.), the data recorded during that period won&#x2019;t be
uploaded until the device comes online again. This means that data might
arrive with an event-time skew of minutes, hours, days, weeks, or more. It&#x2019;s
essentially impossible to draw any sort of useful inferences from such a
dataset when windowed by processing time.</p>
<p>As another example, many distributed input sources might <em>seem</em> to provide
event-time ordered (or very nearly so) data when the overall system is
healthy. Unfortunately, the fact that event-time skew is low for the input
source when healthy does not mean it will always stay that way. Consider a
global service that processes data collected on multiple continents. If network
issues across a bandwidth-constrained transcontinental line (which, sadly, are
surprisingly common) further decrease bandwidth and/or increase latency,
suddenly a portion of your input data might begin arriving with much greater
skew than before. If you are windowing those data by processing time, your
windows are no longer representative of the data that actually occurred within
them; instead, they represent the windows of time as the events arrived at the
processing pipeline, which is some arbitrary mix of old and current data.</p>
<p>What we really want in both of those cases is to window data by their event
times in a way that is robust to the order of arrival of events. What we really
want is event-time windowing.</p>
<p><em>Windowing by event time</em></p>
<p>Event-time windowing is what you use when you need to observe a data
source in finite chunks that reflect the times at which those events actually
happened. It&#x2019;s the gold standard of windowing. Prior to 2016, most data
processing systems in use lacked native support for it (though any system
with a decent consistency model, like Hadoop or Spark Streaming 1.x, could
act as a reasonable substrate for building such a windowing system). I&#x2019;m
happy to say that the world of today looks very different, with multiple
systems, from Flink to Spark to Storm to Apex, natively supporting event-</p>
<p>time windowing of some sort.</p>
<p>Figure 1-10 shows an example of windowing an unbounded source into one-
hour fixed windows.</p>
<pre><code>Figure 1-10. Windowing into fixed windows by event time. Data are collected into windows
based on the times at which they occurred. The black arrows call out example data that
arrived in processing-time windows that differed from the event-time windows to which
they belonged.
</code></pre><p>The black arrows in Figure 1-10 call out two particularly interesting pieces of
data. Each arrived in processing-time windows that did not match the event-
time windows to which each bit of data belonged. As such, if these data had
been windowed into processing-time windows for a use case that cared about
event times, the calculated results would have been incorrect. As you would
expect, event-time correctness is one nice thing about using event-time
windows.</p>
<p>Another nice thing about event-time windowing over an unbounded data
source is that you can create dynamically sized windows, such as sessions,
without the arbitrary splits observed when generating sessions over fixed
windows (as we saw previously in the sessions example from &#x201C;Unbounded
Data: Streaming&#x201D;), as demonstrated in Figure 1-11.</p>
<pre><code>Figure 1-11. Windowing into session windows by event time. Data are collected into
session windows capturing bursts of activity based on the times that the corresponding
events occurred. The black arrows again call out the temporal shuffle necessary to put the
data into their correct event-time locations.
</code></pre><p>Of course, powerful semantics rarely come for free, and event-time windows
are no exception. Event-time windows have two notable drawbacks due to
the fact that windows must often live longer (in processing time) than the
actual length of the window itself:</p>
<p>Buffering</p>
<pre><code>Due to extended window lifetimes, more buffering of data is required.
Thankfully, persistent storage is generally the cheapest of the resource
types most data processing systems depend on (the others being primarily
CPU, network bandwidth, and RAM). As such, this problem is typically
much less of a concern than you might think when using any well-
designed data processing system with strongly consistent persistent state
and a decent in-memory caching layer. Also, many useful aggregations
do not require the entire input set to be buffered (e.g., sum or average),
but instead can be performed incrementally, with a much smaller,
intermediate aggregate stored in persistent state.
</code></pre><p>Completeness</p>
<pre><code>Given that we often have no good way of knowing when we&#x2019;ve seen all
of the data for a given window, how do we know when the results for the
window are ready to materialize? In truth, we simply don&#x2019;t. For many
types of inputs, the system can give a reasonably accurate heuristic
estimate of window completion via something like the watermarks found
</code></pre><pre><code>in MillWheel, Cloud Dataflow, and Flink (which we talk about more in
Chapters 3 and 4 ). But for cases in which absolute correctness is
paramount (again, think billing), the only real option is to provide a way
for the pipeline builder to express when they want results for windows to
be materialized and how those results should be refined over time.
Dealing with window completeness (or lack thereof) is a fascinating topic
but one perhaps best explored in the context of concrete examples, which
we look at next.
</code></pre>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="section1.1.html" class="navigation navigation-prev " aria-label="Previous page: Section1.1 Terminology: What Is Streaming?">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="summary.html" class="navigation navigation-next " aria-label="Next page: Summary">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Section1.2 Data Processing Patterns","level":"1.3.2","depth":2,"next":{"title":"Summary","level":"1.3.3","depth":2,"path":"chapter1/summary.md","ref":"chapter1/summary.md","articles":[]},"previous":{"title":"Section1.1 Terminology: What Is Streaming?","level":"1.3.1","depth":2,"path":"chapter1/section1.1.md","ref":"chapter1/section1.1.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"chapter1/section1.2.md","mtime":"2019-10-03T11:16:32.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-10-03T07:23:23.538Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

